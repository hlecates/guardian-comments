{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7adafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'data_path': '../jigsaw-toxic-comment-classification-challenge/train.csv/train.csv',\n",
    "    'model_base_dir': 'model',\n",
    "    'max_features': 200000, \n",
    "    'sequence_length': 1800, \n",
    "    'embedding_dim': 32,\n",
    "    'lstm_units': 32,\n",
    "    'batch_size': 16,\n",
    "    'epochs': 3,\n",
    "    'validation_split': 0.2,\n",
    "    'test_split': 0.1,\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(CONFIG['random_seed'])\n",
    "np.random.seed(CONFIG['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5451455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and vectorizer\n",
    "\n",
    "# Create subdirectory for this epoch run (e.g., 'models/01_epochs/')\n",
    "epoch_dir = os.path.join(CONFIG['model_base_dir'], f\"{CONFIG['epochs']:02d}_epochs\")\n",
    "\n",
    "# Define paths\n",
    "model_path = os.path.join(epoch_dir, 'toxicity.keras')\n",
    "vectorizer_path = os.path.join(epoch_dir, 'vectorizer.pkl')\n",
    "\n",
    "# Load the saved model and vectorizer\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "with open(vectorizer_path, 'rb') as f:\n",
    "    loaded_vectorizer = pickle.load(f)\n",
    "\n",
    "if loaded_model:\n",
    "    print(f\"Loaded model from {model_path}\")\n",
    "else:\n",
    "    print(f\"Failed to load model from {model_path}\")\n",
    "\n",
    "if loaded_vectorizer:\n",
    "    print(f\"Loaded vectorizer from {vectorizer_path}\")\n",
    "else:\n",
    "    print(f\"Failed to load vectorizer from {vectorizer_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c036ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(f\"Loading data from: {CONFIG['data_path']}\")\n",
    "df = pd.read_csv(CONFIG['data_path'])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d18254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "toxicity_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# Prepare data\n",
    "X = df['comment_text'].values\n",
    "y = df[toxicity_columns].values\n",
    "\n",
    "print(f\"Input shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Number of toxicity categories: {len(toxicity_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94983fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text\n",
    "print(\"Vectorizing text data\")\n",
    "vectorized_text = loaded_vectorizer(X)\n",
    "print(f\"Vectorized text shape: {vectorized_text.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5586e6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow dataset\n",
    "print(\"Creating TensorFlow dataset\")\n",
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000, seed=CONFIG['random_seed'])\n",
    "dataset = dataset.batch(CONFIG['batch_size'])\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "print(f\"Total dataset size: {dataset_size} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dfd3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_size = int(dataset_size * (1 - CONFIG['validation_split'] - CONFIG['test_split']))\n",
    "val_size = int(dataset_size * CONFIG['validation_split'])\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "remaining_dataset = dataset.skip(train_size)\n",
    "val_dataset = remaining_dataset.take(val_size)\n",
    "test_dataset = remaining_dataset.skip(val_size)\n",
    "\n",
    "print(f\"Training batches: {train_size}\")\n",
    "print(f\"Validation batches: {val_size}\")\n",
    "print(f\"Test batches: {test_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Get predictions and true labels from test_dataset\n",
    "y_true = []\n",
    "y_pred_probs = []\n",
    "\n",
    "for batch in test_dataset:\n",
    "    X_batch, y_batch = batch\n",
    "    y_true.append(y_batch.numpy())\n",
    "    y_pred_probs.append(loaded_model.predict(X_batch, verbose=0))\n",
    "\n",
    "# Stack into arrays\n",
    "y_true = np.vstack(y_true)\n",
    "y_pred_probs = np.vstack(y_pred_probs)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4643da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure directory exists\n",
    "save_dir = \"../docs\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save to file\n",
    "save_path = os.path.join(save_dir, \"confusion_matrix.png\")\n",
    "\n",
    "# Define class names\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# Change index `i` for different labels (0 = toxic, 1 = severe_toxic, etc.)\n",
    "i = class_names.index(\"toxic\")\n",
    "cm = confusion_matrix(y_true[:, i], y_pred[:, i])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not toxic\", \"Toxic\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix: {class_names[i].capitalize()}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
